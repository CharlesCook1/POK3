{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.11.11)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Charger le modèle linguistique français de spaCy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "DataFrame = pd.read_excel(\"/Users/charlescook/Desktop/Avis_bar.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les lignes où il manque des avis ou des notes \n",
    "DataFrame = DataFrame.dropna(subset=[\"Avis\", \"Note\"])\n",
    "DataFrame[\"Note\"] = pd.to_numeric(DataFrame[\"Note\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des avis\n",
    "def nettoyage_prealable(text):\n",
    "    # Conversion en minuscule\n",
    "    text = text.lower()\n",
    "    # Supprimer les caractères spéciaux\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    # Retirer les espaces multiples\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "DataFrame[\"Avis\"] = DataFrame[\"Avis\"].apply(nettoyage_prealable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traitement avec spaCy : tokenisation, suppression des stopwords et lemmatisation\n",
    "def spacy_process(text):\n",
    "    doc = nlp(text) # Création du doc qui contient des tokens, des informations grammaticales sur le mot\n",
    "    tokens = [\n",
    "        token.lemma_  # Lemmatisation (transformationd des verbes en infinitif par exemple)\n",
    "        for token in doc\n",
    "        if not token.is_stop and not token.is_punct  # Retirer stopwords et ponctuation\n",
    "    ]\n",
    "    return tokens\n",
    "\n",
    "DataFrame[\"Tokens\"] = DataFrame[\"Avis\"].apply(spacy_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstituer les avis nettoyés et lemmatisés\n",
    "DataFrame[\"Cleaned_Avis\"] = DataFrame[\"Tokens\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.to_excel(\"/Users/charlescook/Desktop/resultats_modifies_bar.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurer TextBlob pour le français\n",
    "tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "\n",
    "# Charger le fichier Excel modifié\n",
    "file_path = \"/Users/charlescook/Desktop/resultats_modifies_bar.xlsx\"  # Remplacez par le chemin correct\n",
    "colonne = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour analyser les sentiments avec TextBlob\n",
    "def analyze_sentiment(text): # en entrée on prend un chaâine de caractères\n",
    "    blob = tb(text) # objet qui analyse le texte notamment la polarité et la subjectivité\n",
    "    return blob.sentiment # renvoie un tuple contenant polarité et subjectivité\n",
    "# Appliquer l'analyse de sentiment\n",
    "colonne[\"Sentiment\"] = colonne[\"Cleaned_Avis\"].apply(lambda x: analyze_sentiment(x) if isinstance(x, str) else None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer la polarité et la subjectivité dans deux colonnes distinctes\n",
    "colonne[\"Polarité\"] = colonne[\"Sentiment\"].apply(lambda x: x[0] if x else None)  # Polarité : entre -1 et 1\n",
    "colonne[\"Subjectivité\"] = colonne[\"Sentiment\"].apply(lambda x: x[1] if x else None)  # Subjectivité : entre 0 et 1\n",
    "\n",
    "# Supprimer la colonne intermédiaire \"Sentiment\"\n",
    "colonne = colonne.drop(columns=[\"Sentiment\"])\n",
    "\n",
    "# Sauvegarder les résultats dans un nouveau fichier Excel\n",
    "output_path = \"/Users/charlescook/Desktop/résultats_avec_sentiments.xlsx\"  # Chemin pour le fichier de sortie\n",
    "colonne.to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret import clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame = pd.read_excel(\"/Users/charlescook/Desktop/Avis_bar.xlsx\")\n",
    "ce = clustering.ClusteringExperiment()\n",
    "\n",
    "ce.setup(data=DataFrame,text_features=['Avis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = ce.create_model('kmeans',num_clusters=2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "DataFrame = pd.read_excel(\"/Users/charlescook/Desktop/Avis_bar.xlsx\")\n",
    "\n",
    "# Sélectionner un échantillon de 10 avis\n",
    "sampled_df = DataFrame.sample(n=10, random_state=123)\n",
    "\n",
    "# Initialiser l'expérience de clustering sur l'échantillon\n",
    "ce = clustering.ClusteringExperiment()\n",
    "\n",
    "# Configurer les données\n",
    "ce.setup(data=sampled_df, text_features=['Avis'])\n",
    "\n",
    "# Créer le modèle de clustering K-means\n",
    "km = ce.create_model('kmeans', num_clusters=2, random_state=123)\n",
    "\n",
    "# Prédire les clusters pour l'échantillon\n",
    "cluster_labels = ce.predict_model(km)\n",
    "\n",
    "# Ajouter la colonne des clusters au DataFrame échantillonné\n",
    "sampled_df['Cluster'] = cluster_labels['Cluster']\n",
    "\n",
    "# Sauvegarder l'échantillon avec la colonne des clusters dans un nouveau fichier Excel\n",
    "sampled_df.to_excel(\"/Users/charlescook/Desktop/Avis_bar_sampled_with_clusters.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
